{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Long-Term Daily Google Trends Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters to your liking\n",
    "start_date= date(2015, 1, 1)\n",
    "end_date= date(2019, 1, 1)\n",
    "key_word = '' # use one key word\n",
    "_cat = 0\n",
    "_geo = ''\n",
    "_gprop = ''\n",
    "_hl = 'en-US'\n",
    "_tz = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source for this function: https://stackoverflow.com/questions/10688006/generate-a-list-of-datetimes-between-an-interval\n",
    "def perdelta(start, end, delta):\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr\n",
    "        curr += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a list of dates with 90 day intervals\n",
    "dates=[]\n",
    "for res in perdelta(start_date, end_date, timedelta(days=90)):\n",
    "    dates.append(res)  \n",
    "dates.append(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gettingt the data for the individual time frames and adding them to a list\n",
    "appended_data = []\n",
    "for i in range(len(dates)-1):\n",
    "    _timeframe = str(dates[i]) + ' ' + str(dates[i+1])\n",
    "    totalTrend = TrendReq(hl=_hl, tz=_tz)\n",
    "    totalTrend.build_payload([key_word], cat=_cat, timeframe=_timeframe, geo=_geo, gprop=_gprop)\n",
    "    totalTrend = totalTrend.interest_over_time()\n",
    "    appended_data.append(totalTrend)\n",
    "#   print(totalTrend.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting the values of the individual time-frames\n",
    "for i in  range(len(appended_data)-1):\n",
    "    x = appended_data[i][key_word].tail(1)\n",
    "    y = appended_data[i+1][key_word].head(1)\n",
    "    factor = float(x/y)\n",
    "    appended_data[i+1][key_word] = appended_data[i+1][key_word] * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating all the dfs to one complete dataframe\n",
    "appended_df = pd.concat(appended_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the duplicated indexes/rows\n",
    "appended_df = appended_df[~appended_df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the daily data as a csv\n",
    "appended_df.to_csv('daily_gtrends.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
